= Creating your first AI Java application with Quarkus and LangChain4j

You will learn how to create a simple RESTful Java AI application that asks a large language model (LLM, or genAI) to write a short poem based on a topic provided by the user. The service responds to GET requests made to the `http://localhost:8080/poems/{topic}/{lines}` URL. The user enters the topic and length of the desired poem; for example `http://localhost:8080/poems/stars/5`, to generate a poem such as:

----
In velvet skies, the stars do dance,
A million whispers, a cosmic romance.
They weave tales of old, in shimmering light,
Guiding lost souls through the velvet night.
In their glow, the universe finds its chance.
----

You will create a Java class and a Java interface. The class represents a resource which defines the application's endpoint and calls the AI model by using the interface to implement an AI service. The AI service uses the parameter values passed in through the endpoint to build a prompt, a natural language text request, and sends it to the AI.

The AI (the large language model, or LLM) parses the prompt and returns a poem according to the topic and number of lines requested in the prompt. LLMs are AI models that are trained to generate output based on the natural language requests they receive. The input and output of LLMs are usually text, as in this application, but some LLMs specialise in other formats such as images or video.

Much of the work needed to build the prompt and to connect to the LLM in order to send the request and get a response is handled for you by LangChain4j, an open source extension to Quarkus.


== Creating the AI service

The AI service provides an abstraction layer to make it easier to write a Java application that interacts with an LLM. The AI service builds the prompts to send to the LLM and receives the responses from the LLM on behalf of the application. The application needs only minimal configuration to connect to the LLM because the AI service handles the connection details. AI services can manage other information too, including chat memory and toolboxes, which will be explored in other guides.

Create the `AiPoemService.java` interface:

[source,java,linenums]
----
include::src/main/java/org/acme/AiPoemService.java[]
----
<1> Implements the interface as an AI service which can connect to the LLM that is configured in the `resources/application.properties` file.
<2> Defines the system message, which provides the context of the prompt. In this case, the system message instructs the LLM to take the role of a professional poet and to display the generated poem in well-formed HTML with line breaks so that it renders neatly when viewed in a web browser. The system message often includes examples of the response to be generated by the LLM but that isn't necessary here.
<3> Defines the user message, which provides the question that the application user is asking the LLM. The user message in this case includes placeholders, `{topic}` and `{length}`, which receive the user's chosen values as entered in the endpoint.
<4> Starts an exchange between the application and the LLM, sending the system message and then the user message. The `writeAPoem()` method is called by the `showMeAPoem()` method in the Poems class.

== Creating the RESTful resource

The RESTful resource defines the endpoint of your RESTful service. When a GET request is made to the endpoint, the `showMeAPoem()` method runs and causes the writeAPoem() method in the AI service to send a request to the LLM.

In this application, the resource class defines the endpoint that receives the user's input (choice of topic and number of lines in the poem) and then passes it to the AI service to include in its request to the LLM.

Create the `Poems.java` class:

[source,java,linenums]
----
include::src/main/java/org/acme/Poems.java[]
----
<1> Implements the AiPoemService interface as aiPoemService.
<2> Defines the RESTful endpoint that takes the values of the variables that are used by the AI service to replace the placeholders in the user message when building the prompt.
<3> Declares the showMeAPoem() method which takes two arguments, `mytopic` and `lines` (because there is more than one argument, you must explicitly annotate each of them). When a GET request is made to the `/poems/{mytopic}/{lines}` endpoint, the values of the `{mytopic}` and `{lines}` parts of the endpoint are passed to the method's `mytopic` and `lines` arguments.
<4> The `showMeaPoem()` method returns the result of calling the AI service's `writeAPoem()` method with the values received from the endpoint. Calling the `writeAPoem()` method causes these values to be added to the user message as part of the prompt that the AI service sends to the LLM. The response from the LLM is then displayed in HTML.

== Configuring the application

Connecting to an LLM is greatly simplified by using LangChain4j. For this application, Quarkus uses the link:https://quarkus.io/extensions/io.quarkiverse.langchain4j/quarkus-langchain4j-openai/[Quarkus LangChain4j OpenAI extension], which is configured in the `pom.xml`. You then need only set the API key and the base URL properties for the LLM; in this case, you can use the value `demo` to get limited demo access to the LLM which is sufficient for this application:

[source,linenums]
----
include::src/main/resources/application.properties[]
----


== Running the application

If you have link:https://quarkus.io/get-started/[installed the Quarkus CLI (see Step 1)], run the following command to start Quarkus in dev mode:

----
quarkus dev
----

Otherwise, run the following Maven command which starts the application in dev mode:

----
./mvnw quarkus:dev
----

Any changes you make to the application are automatically rebuilt and re-deployed.

Request the endpoint with the values you choose replacing the template placeholders. For example, request a poem of 5 lines about stars with the URI `http://localhost:8080/poems/stars/5`. The HTML request in the system message means that it should display neatly in a web browser.

Alternatively, run the following curl command:

----
curl -w "\n" http://localhost:8080/poems/stars/5
----

Notice that there is a slight pause while the LLM responds, but then the application returns a short poem on the chosen topic and of the requested length.

== Where next?

You have now created your first AI Java application and run it on Quarkus with LangChain4j. 

Next, you can learn more about writing AI Java applications with Quarkus and LangChain4j in the link:https://redhat-developer-demos.github.io/quarkus-tutorial/quarkus-tutorial/17_ai_intro.html[Quarkus and AI tutorial].